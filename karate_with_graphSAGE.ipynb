{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from dgl.data import DGLDataset, CoraGraphDataset\n",
    "import dgl.function as fn\n",
    "import pandas as pd\n",
    "from colorama import Fore\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(nn.Module):\n",
    "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat : int\n",
    "        Input feature size.\n",
    "    out_feat : int\n",
    "        Output feature size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_feat:int, out_feat:int):\n",
    "        super(SAGEConv, self).__init__()\n",
    "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
    "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"Forward computation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : Graph\n",
    "            The input graph.\n",
    "        h : Tensor\n",
    "            The input node feature.\n",
    "        \"\"\"\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # update_all is a message passing API.\n",
    "            g.update_all(message_func = fn.copy_u('h', 'm'), \n",
    "                         reduce_func = fn.mean('m', 'h_N'))\n",
    "            h_N = g.ndata['h_N']\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            return self.linear(h_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats)\n",
    "        self.conv2 = SAGEConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KarateClubGraphDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='karate_club')\n",
    "        \n",
    "    def __len__(self): return 1\n",
    "    def __getitem__(self, i): return self.graph\n",
    "    \n",
    "    def process(self):\n",
    "        #NOTE download data\n",
    "        # urlretrieve('https://data.dgl.ai/tutorial/dataset/members.csv', './members.csv')\n",
    "        # urlretrieve('https://data.dgl.ai/tutorial/dataset/interactions.csv', './interactions.csv')\n",
    "        nodes_data = pd.read_csv('dataset/Karate_Club/members.csv')\n",
    "        edges_data = pd.read_csv('dataset/Karate_Club/interactions.csv')\n",
    "        n_nodes  = nodes_data.shape[0]\n",
    "        \n",
    "        node_labels  = torch.tensor(nodes_data['Club'].astype('category').cat.codes.to_list())\n",
    "        node_features = torch.from_numpy(nodes_data['Age'].to_numpy()).reshape(n_nodes, 1)\n",
    "        edge_features = torch.from_numpy(edges_data['Weight'].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data['Src'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['Dst'].to_numpy())\n",
    "        \n",
    "        #NOTE create graph with nodes and edges feature\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=n_nodes)\n",
    "        self.graph = dgl.to_bidirected(self.graph)      # convert to undirected\n",
    "        self.graph.ndata['feat'] = node_features        #NOTE learnable\n",
    "        self.graph.ndata['label'] = node_labels\n",
    "        self.graph.ndata['node_features'] = nn.Parameter(torch.randn(self.graph.num_nodes(), 10))\n",
    "\n",
    "        self.graph.edata['weight'] = edge_features\n",
    "\n",
    "        #NOTE If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val  = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask  = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask  = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train:n_train + n_val] = True\n",
    "        test_mask[n_train + n_val:] = True\n",
    "        self.graph.ndata['train_mask'] = train_mask\n",
    "        self.graph.ndata['val_mask'] = val_mask\n",
    "        self.graph.ndata['test_mask'] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CoraGraphDataset(verbose=False)\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KarateClubGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(g.ndata['label'].tolist()))   #2\n",
    "model = GraphSAGE(g.ndata['feat'].shape[1], 16, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g:DGLDataset, model:nn.Module, epochs:int):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    all_logits = []\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat'].float()  #BUG https://github.com/dmlc/dgl/issues/2299\n",
    "    labels = g.ndata['label']\n",
    "    \n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(1, epochs+1):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "        \n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # NOTE that we should only compute the losses of the nodes in the training set,\n",
    "        # i.e. with train_mask 1.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_logits.append(logits.detach())\n",
    "\n",
    "        if not e % 25:\n",
    "            print('In epoch {:3d}, loss: {:.4f}, val acc: {:.4f} (best {:.4f}), test acc: {:.4f} (best {:.4f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agent/anaconda3/envs/graph/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch  25, loss: 0.9192, val acc: 0.8333 (best 0.8333), test acc: 0.7500 (best 1.0000)\n",
      "In epoch  50, loss: 0.5191, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch  75, loss: 0.4959, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch 100, loss: 0.4880, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch 125, loss: 0.4845, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch 150, loss: 0.4813, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch 175, loss: 0.4789, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n",
      "In epoch 200, loss: 0.4760, val acc: 0.1667 (best 0.8333), test acc: 0.0000 (best 1.0000)\n"
     ]
    }
   ],
   "source": [
    "train(g, model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('graph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d620334016f14c166285ee8528a11ee9bc398b5cacff66726993ff9e9a83d46b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
